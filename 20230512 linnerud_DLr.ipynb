{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fa1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats  # 과학용 계산 라이브러리\n",
    "from sklearn.datasets import load_boston  # 사이킷런 데이타셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8bb3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "lin = load_linnerud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0675071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[  5., 162.,  60.],\n",
       "        [  2., 110.,  60.],\n",
       "        [ 12., 101., 101.],\n",
       "        [ 12., 105.,  37.],\n",
       "        [ 13., 155.,  58.],\n",
       "        [  4., 101.,  42.],\n",
       "        [  8., 101.,  38.],\n",
       "        [  6., 125.,  40.],\n",
       "        [ 15., 200.,  40.],\n",
       "        [ 17., 251., 250.],\n",
       "        [ 17., 120.,  38.],\n",
       "        [ 13., 210., 115.],\n",
       "        [ 14., 215., 105.],\n",
       "        [  1.,  50.,  50.],\n",
       "        [  6.,  70.,  31.],\n",
       "        [ 12., 210., 120.],\n",
       "        [  4.,  60.,  25.],\n",
       "        [ 11., 230.,  80.],\n",
       "        [ 15., 225.,  73.],\n",
       "        [  2., 110.,  43.]]),\n",
       " 'feature_names': ['Chins', 'Situps', 'Jumps'],\n",
       " 'target': array([[191.,  36.,  50.],\n",
       "        [189.,  37.,  52.],\n",
       "        [193.,  38.,  58.],\n",
       "        [162.,  35.,  62.],\n",
       "        [189.,  35.,  46.],\n",
       "        [182.,  36.,  56.],\n",
       "        [211.,  38.,  56.],\n",
       "        [167.,  34.,  60.],\n",
       "        [176.,  31.,  74.],\n",
       "        [154.,  33.,  56.],\n",
       "        [169.,  34.,  50.],\n",
       "        [166.,  33.,  52.],\n",
       "        [154.,  34.,  64.],\n",
       "        [247.,  46.,  50.],\n",
       "        [193.,  36.,  46.],\n",
       "        [202.,  37.,  62.],\n",
       "        [176.,  37.,  54.],\n",
       "        [157.,  32.,  52.],\n",
       "        [156.,  33.,  54.],\n",
       "        [138.,  33.,  68.]]),\n",
       " 'target_names': ['Weight', 'Waist', 'Pulse'],\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _linnerrud_dataset:\\n\\nLinnerrud dataset\\n-----------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20\\n    :Number of Attributes: 3\\n    :Missing Attribute Values: None\\n\\nThe Linnerud dataset is a multi-output regression dataset. It consists of three\\nexercise (data) and three physiological (target) variables collected from\\ntwenty middle-aged men in a fitness club:\\n\\n- *physiological* - CSV containing 20 observations on 3 physiological variables:\\n   Weight, Waist and Pulse.\\n- *exercise* - CSV containing 20 observations on 3 exercise variables:\\n   Chins, Situps and Jumps.\\n\\n.. topic:: References\\n\\n  * Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris:\\n    Editions Technic.\\n',\n",
       " 'data_filename': 'linnerud_exercise.csv',\n",
       " 'target_filename': 'linnerud_physiological.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e02fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(lin.data, columns = lin.feature_names)\n",
    "df_labels = pd.DataFrame(lin.target, columns = lin.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90c83399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chins</th>\n",
       "      <th>Situps</th>\n",
       "      <th>Jumps</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chins  Situps  Jumps  Weight  Waist  Pulse\n",
       "15   12.0   210.0  120.0   202.0   37.0   62.0\n",
       "16    4.0    60.0   25.0   176.0   37.0   54.0\n",
       "17   11.0   230.0   80.0   157.0   32.0   52.0\n",
       "18   15.0   225.0   73.0   156.0   33.0   54.0\n",
       "19    2.0   110.0   43.0   138.0   33.0   68.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(linnerud.data, columns=linnerud.feature_names),\n",
    "                pd.DataFrame(linnerud.target, columns=linnerud.target_names)],\n",
    "               axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fe9d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:3].values\n",
    "y = df.iloc[:,3].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f1c9418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5., 162.,  60.],\n",
       "       [  2., 110.,  60.],\n",
       "       [ 12., 101., 101.],\n",
       "       [ 12., 105.,  37.],\n",
       "       [ 13., 155.,  58.],\n",
       "       [  4., 101.,  42.],\n",
       "       [  8., 101.,  38.],\n",
       "       [  6., 125.,  40.],\n",
       "       [ 15., 200.,  40.],\n",
       "       [ 17., 251., 250.],\n",
       "       [ 17., 120.,  38.],\n",
       "       [ 13., 210., 115.],\n",
       "       [ 14., 215., 105.],\n",
       "       [  1.,  50.,  50.],\n",
       "       [  6.,  70.,  31.],\n",
       "       [ 12., 210., 120.],\n",
       "       [  4.,  60.,  25.],\n",
       "       [ 11., 230.,  80.],\n",
       "       [ 15., 225.,  73.],\n",
       "       [  2., 110.,  43.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44cf0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([191., 189., 193., 162., 189., 182., 211., 167., 176., 154., 169.,\n",
       "       166., 154., 247., 193., 202., 176., 157., 156., 138.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72fc9e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 128)               512       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,393\n",
      "Trainable params: 11,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (3,)))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1)) \n",
    "model.compile(optimizer = 'rmsprop', loss = 'mae', metrics = ['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6976a6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 193.9350 - mae: 193.9350 - val_loss: 168.9301 - val_mae: 168.9301\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 186.2780 - mae: 186.2780 - val_loss: 163.3647 - val_mae: 163.3647\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 180.9214 - mae: 180.9214 - val_loss: 161.2349 - val_mae: 161.2349\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 178.8710 - mae: 178.8710 - val_loss: 158.6143 - val_mae: 158.6143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 176.6528 - mae: 176.6528 - val_loss: 156.0773 - val_mae: 156.0773\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 174.4350 - mae: 174.4350 - val_loss: 154.0184 - val_mae: 154.0184\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 172.2158 - mae: 172.2158 - val_loss: 150.8234 - val_mae: 150.8234\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 169.4210 - mae: 169.4210 - val_loss: 147.6531 - val_mae: 147.6531\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 166.2278 - mae: 166.2278 - val_loss: 144.6868 - val_mae: 144.6868\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 163.4530 - mae: 163.4530 - val_loss: 140.9221 - val_mae: 140.9221\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 159.7666 - mae: 159.7666 - val_loss: 136.8026 - val_mae: 136.8026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 155.8605 - mae: 155.8605 - val_loss: 131.9396 - val_mae: 131.9396\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 151.1323 - mae: 151.1323 - val_loss: 126.7117 - val_mae: 126.7117\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 146.1344 - mae: 146.1344 - val_loss: 121.1807 - val_mae: 121.1807\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 140.9051 - mae: 140.9051 - val_loss: 114.9087 - val_mae: 114.9087\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 134.9093 - mae: 134.9093 - val_loss: 108.1904 - val_mae: 108.1904\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 128.3760 - mae: 128.3760 - val_loss: 100.8033 - val_mae: 100.8033\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 121.3230 - mae: 121.3230 - val_loss: 93.1881 - val_mae: 93.1881\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 113.9139 - mae: 113.9139 - val_loss: 85.0395 - val_mae: 85.0395\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 107.0522 - mae: 107.0522 - val_loss: 77.8713 - val_mae: 77.8713\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 102.0592 - mae: 102.0592 - val_loss: 69.9891 - val_mae: 69.9891\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 96.5293 - mae: 96.5293 - val_loss: 61.5254 - val_mae: 61.5254\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 90.5151 - mae: 90.5151 - val_loss: 52.7424 - val_mae: 52.7424\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 85.2080 - mae: 85.2080 - val_loss: 50.9757 - val_mae: 50.9757\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 83.3833 - mae: 83.3833 - val_loss: 50.1512 - val_mae: 50.1512\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 82.8801 - mae: 82.8801 - val_loss: 49.3127 - val_mae: 49.3127\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 82.3457 - mae: 82.3457 - val_loss: 48.2881 - val_mae: 48.2881\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 81.8119 - mae: 81.8119 - val_loss: 47.1817 - val_mae: 47.1817\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 81.1735 - mae: 81.1735 - val_loss: 46.0550 - val_mae: 46.0550\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 80.4889 - mae: 80.4889 - val_loss: 44.7808 - val_mae: 44.7808\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 79.7282 - mae: 79.7282 - val_loss: 43.4845 - val_mae: 43.4845\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 79.1029 - mae: 79.1029 - val_loss: 43.4751 - val_mae: 43.4751\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 78.9979 - mae: 78.9979 - val_loss: 41.8814 - val_mae: 41.8814\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 78.9716 - mae: 78.9716 - val_loss: 41.9945 - val_mae: 41.9945\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 78.8598 - mae: 78.8598 - val_loss: 42.0981 - val_mae: 42.0981\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 78.7456 - mae: 78.7456 - val_loss: 42.1992 - val_mae: 42.1992\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 78.6290 - mae: 78.6290 - val_loss: 42.2970 - val_mae: 42.2970\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 78.5115 - mae: 78.5115 - val_loss: 42.3989 - val_mae: 42.3989\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 78.3905 - mae: 78.3905 - val_loss: 42.4891 - val_mae: 42.4891\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 78.2662 - mae: 78.2662 - val_loss: 42.5740 - val_mae: 42.5740\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 78.1399 - mae: 78.1399 - val_loss: 42.6543 - val_mae: 42.6543\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 78.0228 - mae: 78.0228 - val_loss: 44.8331 - val_mae: 44.8331\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 78.0187 - mae: 78.0187 - val_loss: 45.0314 - val_mae: 45.0314\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 77.8596 - mae: 77.8596 - val_loss: 45.1978 - val_mae: 45.1978\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 77.7047 - mae: 77.7047 - val_loss: 45.3626 - val_mae: 45.3626\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 77.5420 - mae: 77.5420 - val_loss: 45.5464 - val_mae: 45.5464\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 77.3758 - mae: 77.3758 - val_loss: 45.7498 - val_mae: 45.7498\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 77.1960 - mae: 77.1960 - val_loss: 45.9612 - val_mae: 45.9612\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 77.0155 - mae: 77.0155 - val_loss: 46.2134 - val_mae: 46.2134\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 76.8264 - mae: 76.8264 - val_loss: 46.5128 - val_mae: 46.5128\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 76.6302 - mae: 76.6302 - val_loss: 46.8144 - val_mae: 46.8144\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 76.4252 - mae: 76.4252 - val_loss: 47.1768 - val_mae: 47.1768\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 76.2184 - mae: 76.2184 - val_loss: 47.5478 - val_mae: 47.5478\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 76.0055 - mae: 76.0055 - val_loss: 47.9905 - val_mae: 47.9905\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 75.7833 - mae: 75.7833 - val_loss: 48.4552 - val_mae: 48.4552\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 75.5506 - mae: 75.5506 - val_loss: 48.9562 - val_mae: 48.9562\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 75.3169 - mae: 75.3169 - val_loss: 49.5317 - val_mae: 49.5317\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 75.0680 - mae: 75.0680 - val_loss: 50.1512 - val_mae: 50.1512\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 74.8106 - mae: 74.8106 - val_loss: 50.8423 - val_mae: 50.8423\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 74.5342 - mae: 74.5342 - val_loss: 51.7805 - val_mae: 51.7805\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 74.2210 - mae: 74.2210 - val_loss: 52.4379 - val_mae: 52.4379\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 73.9038 - mae: 73.9038 - val_loss: 53.3544 - val_mae: 53.3544\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 73.5725 - mae: 73.5725 - val_loss: 54.4226 - val_mae: 54.4226\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 73.2174 - mae: 73.2174 - val_loss: 55.4976 - val_mae: 55.4976\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 72.8287 - mae: 72.8287 - val_loss: 56.6762 - val_mae: 56.6762\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 72.4227 - mae: 72.4227 - val_loss: 58.0041 - val_mae: 58.0041\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 71.9963 - mae: 71.9963 - val_loss: 59.4272 - val_mae: 59.4272\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 71.5384 - mae: 71.5384 - val_loss: 60.9945 - val_mae: 60.9945\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 71.0612 - mae: 71.0612 - val_loss: 62.9912 - val_mae: 62.9912\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 70.4485 - mae: 70.4485 - val_loss: 65.0010 - val_mae: 65.0010\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 69.8620 - mae: 69.8620 - val_loss: 67.0055 - val_mae: 67.0055\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 69.2589 - mae: 69.2589 - val_loss: 69.3663 - val_mae: 69.3663\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 68.5861 - mae: 68.5861 - val_loss: 71.7003 - val_mae: 71.7003\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 68.6759 - mae: 68.6759 - val_loss: 62.1510 - val_mae: 62.1510\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 70.5195 - mae: 70.5195 - val_loss: 69.0426 - val_mae: 69.0426\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 67.6382 - mae: 67.6382 - val_loss: 70.5905 - val_mae: 70.5905\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 67.1250 - mae: 67.1250 - val_loss: 72.1576 - val_mae: 72.1576\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 66.5921 - mae: 66.5921 - val_loss: 74.0931 - val_mae: 74.0931\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 66.1019 - mae: 66.1019 - val_loss: 70.4555 - val_mae: 70.4555\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 66.5926 - mae: 66.5926 - val_loss: 77.6217 - val_mae: 77.6217\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 67.4042 - mae: 67.4042 - val_loss: 70.7940 - val_mae: 70.7940\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 67.2186 - mae: 67.2186 - val_loss: 78.9409 - val_mae: 78.9409\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 67.8777 - mae: 67.8777 - val_loss: 73.7446 - val_mae: 73.7446\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 65.3432 - mae: 65.3432 - val_loss: 75.2013 - val_mae: 75.2013\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 64.9138 - mae: 64.9138 - val_loss: 76.6950 - val_mae: 76.6950\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 64.4451 - mae: 64.4451 - val_loss: 78.2152 - val_mae: 78.2152\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 64.3358 - mae: 64.3358 - val_loss: 72.6827 - val_mae: 72.6827\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 68.7329 - mae: 68.7329 - val_loss: 80.0660 - val_mae: 80.0660\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 65.5428 - mae: 65.5428 - val_loss: 75.4790 - val_mae: 75.4790\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 65.5393 - mae: 65.5393 - val_loss: 81.9794 - val_mae: 81.9794\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 67.0812 - mae: 67.0812 - val_loss: 76.0080 - val_mae: 76.0080\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 64.5403 - mae: 64.5403 - val_loss: 81.6991 - val_mae: 81.6991\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 66.8484 - mae: 66.8484 - val_loss: 76.3699 - val_mae: 76.3699\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 64.2193 - mae: 64.2193 - val_loss: 79.8822 - val_mae: 79.8822\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 64.8443 - mae: 64.8443 - val_loss: 76.4678 - val_mae: 76.4678\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 64.7866 - mae: 64.7866 - val_loss: 81.8575 - val_mae: 81.8575\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 66.1051 - mae: 66.1051 - val_loss: 78.4404 - val_mae: 78.4404\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 63.5903 - mae: 63.5903 - val_loss: 79.5399 - val_mae: 79.5399\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 63.3465 - mae: 63.3465 - val_loss: 75.9415 - val_mae: 75.9415\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 66.5776 - mae: 66.5776 - val_loss: 81.5018 - val_mae: 81.5018\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "history = model.fit(X_train, y_train, epochs = N_EPOCHS, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c4a119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 362ms/step - loss: 5677.0391 - mae: 60.0916\n"
     ]
    }
   ],
   "source": [
    "model = build_model() \n",
    "model.fit(X, y, epochs=300, batch_size=32, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c2c30aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.091552734375"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfc9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
